{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "#Utilities\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "#Models\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "\n",
    "#Functionalities\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')\n",
    "parameters = {\n",
    "    \"dataset\":{\n",
    "        \"path\": \"../data/Processed_Data/Demand_Dataset.csv\",\n",
    "        \"trainingSize\": .70,\n",
    "        \"validationSize\": .15,\n",
    "        \"testSize\": .15\n",
    "    },\n",
    "    \"backtesting\":{\n",
    "        \"steps\": 96,\n",
    "        \"fixedTrainSize\": False,\n",
    "        \"refit\": False,\n",
    "    },\n",
    "    \"validation\": {\n",
    "        \"n_splits\" : 10\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoRegressive Models (SKForecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Dataset {Path Dataset}\n",
    "df = pd.read_csv(parameters[\"dataset\"][\"path\"])\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Dataset Separators\n",
    "trainingSize = int((parameters[\"dataset\"][\"validationSize\"] + parameters[\"dataset\"][\"trainingSize\"] ) * df.shape[0])\n",
    "trainingLastDate = str(df.loc[[trainingSize]][\"Date\"].values[0])\n",
    "\n",
    "#Set Date as Index an Data Frequency to 15 mins\n",
    "df = df.set_index(\"Date\")\n",
    "df = df.asfreq(\"15min\")\n",
    "\n",
    "#Split Dataset\n",
    "X_train = df.loc[:trainingLastDate, :].copy()\n",
    "X_test = df.loc[trainingLastDate:, :].copy()\n",
    "\n",
    "#THe first row is repeated\n",
    "X_test = X_test.iloc[1:]\n",
    "\n",
    "#Prints\n",
    "print(f\"Whole Dataset Size: {df.shape[0]}\")\n",
    "print(f\"Trainig Dataset Size: {X_train.shape[0]} From: {X_train.index.min()} to {X_train.index.max()}\")\n",
    "print(f\"Test Dataset Size: {X_test.shape[0]} From: {X_test.index.min()} to {X_test.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=X_train.index, y=X_train[\"Demand\"], mode=\"lines\", name=\"Train\"))\n",
    "fig.add_trace(go.Scatter(x=X_test.index, y=X_test[\"Demand\"], mode=\"lines\", name=\"Test\"))\n",
    "fig.update_layout(\n",
    "    title = \"Dataset Partition\",\n",
    "    xaxis_title = \"Date\",\n",
    "    yaxis_title =\"Demand (MWh)\",\n",
    "    width = 1000,\n",
    "    height = 400,\n",
    "    margin = dict(l=30, r=20, t=35, b=60),\n",
    "    legend = dict(\n",
    "        orientation = \"h\",\n",
    "        yanchor = \"bottom\",\n",
    "        y = 1.05,\n",
    "        xanchor = \"right\",\n",
    "        x=1\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPredictions(dates, y_pred, y_test):\n",
    "    fig = go.Figure()\n",
    "    trace1 = go.Scatter(x=dates, y=y_test, name=\"test\", mode=\"lines\")\n",
    "    trace2 = go.Scatter(x=dates, y=y_pred, name=\"predictions\", mode=\"lines\")\n",
    "    fig.add_trace(trace1)\n",
    "    fig.add_trace(trace2)\n",
    "    fig.update_layout(\n",
    "        title=\"Real value vs Predicted in Test Data\",\n",
    "        xaxis_title=\"Date Time\",\n",
    "        yaxis_title=\"Demand\",\n",
    "        width=1020,\n",
    "        height=450,\n",
    "        margin = dict(l=70, r=20, t=55, b=20),\n",
    "        legend = dict(\n",
    "            orientation = \"h\",\n",
    "            yanchor=\"top\",\n",
    "            y=1.1,\n",
    "            xanchor=\"left\",\n",
    "            x=0.76\n",
    "        )\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_backtesting(model, data, initial_train_size, exog, params):\n",
    "    init = time.time()\n",
    "    forecaster = ForecasterAutoreg(\n",
    "        regressor = model,\n",
    "        transformer_y = StandardScaler(),\n",
    "        lags=24\n",
    "    )\n",
    "    metrics, predictions = backtesting_forecaster(\n",
    "        forecaster = forecaster,\n",
    "        steps = (len(data) - initial_train_size),\n",
    "        y = data[\"Demand\"],\n",
    "        metric = ['mean_absolute_error', 'mean_squared_error'],\n",
    "        exog = exog,\n",
    "        initial_train_size = initial_train_size,\n",
    "        refit = params[\"backtesting\"][\"refit\"],\n",
    "        fixed_train_size = parameters[\"backtesting\"][\"fixedTrainSize\"],\n",
    "        verbose = False,\n",
    "        show_progress = True,\n",
    "        n_jobs='auto'\n",
    "    )\n",
    "    end = time.time()\n",
    "    return predictions, metrics, (end-init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LGBM': LGBMRegressor(n_estimators=100, random_state=123, verbose=-1),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=123, max_depth=10),\n",
    "    'KNNR': KNeighborsRegressor(n_neighbors=20, weights='distance'),\n",
    "    \"SVR\": SVR(kernel='rbf'),\n",
    "    'GBM': GradientBoostingRegressor(n_estimators=100, random_state=123),\n",
    "    'RF': RandomForestRegressor(n_estimators=100, random_state=123),\n",
    "    'ADA': AdaBoostRegressor(n_estimators=100, random_state=123)\n",
    "}\n",
    "results = {}\n",
    "df_exog = df.drop(\"Demand\", axis=1)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    predictions, metrics, model_time = run_backtesting(model, df, len(X_train), df_exog, parameters)\n",
    "    results[model_name] = {\n",
    "        'predictions': predictions,\n",
    "        'MAE': metrics[0],\n",
    "        'RMSE': np.sqrt(metrics[1]),\n",
    "        'Time': model_time\n",
    "    }\n",
    "    print(f\"Model {model_name}: MAE: {metrics[0]}, RMSE: {np.sqrt(metrics[1])}, Time: {model_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lags used as Predictors\n",
    "lags_grid = [1, 48, 96, 96*2, 96*7]\n",
    "\n",
    "#Regressor Hyperparameters\n",
    "param_grid = {\n",
    "    'n_neighbors': [10, 20, 30, 40, 50],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor = KNeighborsRegressor(n_neighbors=5, weights= 'distance'),\n",
    "    transformer_y = StandardScaler(),\n",
    "    lags=24*7\n",
    ")\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "    forecaster = forecaster,\n",
    "    y = df[\"Demand\"],\n",
    "    param_grid = param_grid,\n",
    "    steps = len(X_test),\n",
    "    lags_grid = lags_grid,\n",
    "    exog = df_exog,\n",
    "    refit = parameters[\"backtesting\"][\"refit\"],\n",
    "    metric = [\"mean_squared_error\", 'mean_absolute_error'],\n",
    "    initial_train_size = len(X_train),\n",
    "    n_jobs = 'auto',\n",
    "    verbose = False,\n",
    "    show_progress=True,\n",
    "    return_best = True,\n",
    "    fixed_train_size=parameters['backtesting'][\"fixedTrainSize\"]\n",
    ")\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "    regressor = KNeighborsRegressor(n_neighbors=25, weights= 'uniform'),\n",
    "    transformer_y = StandardScaler(),\n",
    "    lags=24*7\n",
    ")\n",
    "X_train_exog = X_train.drop(\"Demand\", axis=1)\n",
    "forecaster.fit(y=X_train[\"Demand\"], exog=X_train_exog)\n",
    "X_test_exog = X_test.drop(\"Demand\", axis=1)\n",
    "predictions = forecaster.predict(steps=len(X_test_exog), exog=X_test_exog)\n",
    "print(f\"TEST MAE: {mean_absolute_error(X_test[\"Demand\"].values, predictions.values)}, RMSE: {root_mean_squared_error(X_test[\"Demand\"].values, predictions.values)}\")\n",
    "plotPredictions(predictions.index, np.asarray(predictions.values), np.asarray(X_test[\"Demand\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Forecaster\n",
    "forecaster"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
